{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "with open(\"models/vocabulario.pickle\", 'rb') as handle:\n",
    "    vocabulario = pickle.load(handle)\n",
    "with open('models/numatext.pickle', 'rb') as handle:\n",
    "    NumAtext = pickle.load(handle)\n",
    "with open('models/textanum.pickle', 'rb') as handle:\n",
    "    textANum = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builder_model(vocab_size, embedding_dim, rnn_units,batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "                               tf.keras.layers.Embedding(\n",
    "                                   vocab_size,\n",
    "                                   embedding_dim, \n",
    "                                   batch_input_shape = [batch_size,None]),\n",
    "                               tf.keras.layers.GRU(\n",
    "                                   rnn_units,\n",
    "                                   return_sequences=True, \n",
    "                                   stateful=True,\n",
    "                                   recurrent_initializer = 'glorot_uniform'),\n",
    "                               tf.keras.layers.LSTM(\n",
    "                                   rnn_units,\n",
    "                                   return_sequences=True, \n",
    "                                   stateful=True,\n",
    "                                   recurrent_initializer = 'glorot_uniform'),\n",
    "                               tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocabulario)\n",
    "embedding_dim = 512\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/ckpt_8'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './models'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt_{epoch}')\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = builder_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 512)            17920     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (1, None, 256)            591360    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1, None, 256)            525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 35)             8995      \n",
      "=================================================================\n",
      "Total params: 1,143,587\n",
      "Trainable params: 1,143,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string,num_generate = 1000):\n",
    "  input_eval = [textANum[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "  temperature = 1.0\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated.append(NumAtext[predicted_id])\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olor a esta pasado el meses el percha había sértacidad desmás una casa en la misma dirustradas carejas frencas otra las cachada y su crliera de la ida a la mu desbriul sólo no soltó de la tendirle su lugo regrinado a todas clases de su costura consención y sin las haciendos grandes con sus sueltas por la demoraba pero ella no ocera a la hija para pomos ponque esa sopa al falta los se encendería muerto de dud para no salía puas concidencias escabanotes se inmaviales durantes en la casa acasario la cereda florentino ariza esperara a salar la seguir sin embrer la ervancde personal no habían si esto aprovista de la calle era más que vendelos de la caba en la meo de las suscadas contra sus vantos mayor pero florentino ariza menos tratadora de que fue fitaldo amargerando supo desza vivía con fermina babriel víctivo al que nunca hora certiciones y de convernad no las días muchos años a la puusa con su vez y parecía otras las ladedarse d lo y el el tiqueza contarla entonces la espal vez en la escu\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"olor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
